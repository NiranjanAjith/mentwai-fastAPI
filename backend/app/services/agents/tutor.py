"""
Streaming educational response agent providing personalized tutoring content.
Generates contextual responses using educational content and user preferences.
"""

import asyncio
import logging
import time
from typing import AsyncGenerator, Dict, Any, List, Optional

from app.models.chat import UserContext, ClassificationResult
from app.services.tools.llm_client import llm_client
from app.services.context.minimal_context import minimal_context_service

logger = logging.getLogger(__name__)

class TutorAgent:
    """
    Streaming educational response agent for personalized tutoring.
    Generates real-time responses with educational context integration.
    """
    
    def __init__(self):
        self.llm_client = llm_client
        self.context_service = minimal_context_service
        self.max_response_length = 800
        self.streaming_chunk_size = 50
    
    async def generate_streaming_response(
        self,
        query: str,
        context: UserContext,
        classification: ClassificationResult,
        session_id: Optional[str] = None
    ) -> AsyncGenerator[str, None]:
        """
        Generate streaming educational response based on user query and classification.
        Yields text chunks as they're generated by the LLM.
        """
        start_time = time.time()
        
        try:
            # Get relevant educational content in parallel with response generation
            textbook_task = asyncio.create_task(
                self.context_service.get_relevant_textbook_content(
                    query, 
                    context.current_subject, 
                    max_snippets=2
                )
            )
            
            # Build enhanced context for the LLM
            enhanced_context = await self._build_enhanced_context(
                query, context, classification, textbook_task
            )
            
            # Generate streaming response
            chunk_count = 0
            total_content = ""
            
            async for chunk in self.llm_client.generate_streaming_response(
                query=query,
                context=enhanced_context,
                classification=classification.intent
            ):
                if chunk:
                    chunk_count += 1
                    total_content += chunk
                    yield chunk
                    
                    # Add small delay every few chunks to prevent overwhelming
                    if chunk_count % 10 == 0:
                        await asyncio.sleep(0.01)  # 10ms pause
            
            # Log performance metrics
            generation_time = (time.time() - start_time) * 1000
            logger.info(
                f"Response generated: {len(total_content)} chars, "
                f"{chunk_count} chunks, {generation_time:.1f}ms"
            )
            
            # Update session context asynchronously
            if session_id:
                asyncio.create_task(
                    self.context_service.update_session_context(
                        session_id, query, classification.intent, total_content[:100]
                    )
                )
        
        except Exception as e:
            logger.error(f"Streaming response generation failed: {e}")
            error_message = self._get_error_response(e, classification.intent)
            yield error_message
    
    async def _build_enhanced_context(
        self,
        query: str,
        context: UserContext,
        classification: ClassificationResult,
        textbook_task: asyncio.Task
    ) -> Dict[str, Any]:
        """Build enhanced context for LLM with educational content."""
        
        enhanced_context = {
            "subject_area": context.current_subject,
            "difficulty_level": context.difficulty_level,
            "user_preferences": context.learning_preferences,
            "classification": classification.intent,
            "confidence": classification.confidence
        }
        
        # Add session history context
        if context.session_history:
            # Summarize recent interactions
            recent_topics = []
            for interaction in context.session_history[-3:]:  # Last 3 interactions
                if "user_query" in interaction:
                    recent_topics.append(interaction["user_query"][:50])
            
            if recent_topics:
                enhanced_context["recent_topics"] = recent_topics
        
        # Try to get textbook content (with timeout)
        try:
            textbook_content = await asyncio.wait_for(textbook_task, timeout=0.1)
            if textbook_content:
                enhanced_context["relevant_content"] = textbook_content
        except asyncio.TimeoutError:
            logger.debug("Textbook content retrieval timeout, proceeding without")
        except Exception as e:
            logger.warning(f"Failed to get textbook content: {e}")
        
        # Add teaching strategy based on classification
        enhanced_context["teaching_strategy"] = self._get_teaching_strategy(
            classification.intent, context.learning_preferences
        )
        
        return enhanced_context
    
    def _get_teaching_strategy(self, intent: str, preferences: Dict[str, Any]) -> Dict[str, Any]:
        """Get teaching strategy based on intent and user preferences."""
        
        base_strategies = {
            "explain": {
                "method": "conceptual_explanation",
                "structure": "definition_examples_applications",
                "interaction": "guided_discovery"
            },
            "solve": {
                "method": "step_by_step_solution",
                "structure": "problem_analysis_solution_verification",
                "interaction": "collaborative_problem_solving"
            },
            "clarify": {
                "method": "targeted_clarification",
                "structure": "identify_confusion_address_directly",
                "interaction": "supportive_questioning"
            },
            "example": {
                "method": "demonstration_with_explanation",
                "structure": "example_breakdown_generalization",
                "interaction": "show_and_tell"
            }
        }
        
        strategy = base_strategies.get(intent, base_strategies["explain"])
        
        # Customize based on user preferences
        if preferences.get("step_by_step", True):
            strategy["include_steps"] = True
        
        if preferences.get("include_examples", True):
            strategy["provide_examples"] = True
        
        if preferences.get("explanation_style") == "detailed":
            strategy["detail_level"] = "comprehensive"
        else:
            strategy["detail_level"] = "concise"
        
        return strategy
    
    def _get_error_response(self, error: Exception, intent: str) -> str:
        """Generate appropriate error response based on context."""
        
        error_responses = {
            "explain": "I apologize, but I'm having trouble generating an explanation right now. Could you please rephrase your question or try asking about a specific aspect?",
            "solve": "I'm sorry, but I encountered an issue while working on this problem. Could you break down the problem into smaller parts or provide more specific details?",
            "clarify": "I'm having difficulty processing your clarification request at the moment. Could you ask your question in a different way?",
            "example": "I'm unable to generate examples right now due to a technical issue. Could you specify exactly what type of example would be most helpful?"
        }
        
        return error_responses.get(intent, "I apologize for the technical difficulty. Please try rephrasing your question.")
    
    async def generate_response_preview(
        self,
        query: str,
        context: UserContext,
        classification: ClassificationResult,
        max_words: int = 20
    ) -> str:
        """
        Generate a quick preview of the response for immediate feedback.
        Used while the full streaming response is being generated.
        """
        
        try:
            preview_templates = {
                "explain": "Let me explain {topic}. {topic} is fundamentally about...",
                "solve": "I'll help you solve this step by step. First, let's analyze...",
                "clarify": "I understand you need clarification on {topic}. Let me break it down...",
                "example": "Here's a practical example of {topic}. Consider this scenario..."
            }
            
            # Extract key topic from query (simple approach)
            words = query.split()
            key_terms = [word for word in words if len(word) > 3 and word.isalpha()]
            topic = key_terms[0] if key_terms else "this concept"
            
            template = preview_templates.get(classification.intent, preview_templates["explain"])
            preview = template.format(topic=topic)
            
            # Truncate to max_words
            preview_words = preview.split()[:max_words]
            return " ".join(preview_words) + "..."
            
        except Exception as e:
            logger.warning(f"Failed to generate response preview: {e}")
            return "Let me think about this..."
    
    async def get_response_metadata(
        self,
        query: str,
        context: UserContext,
        classification: ClassificationResult
    ) -> Dict[str, Any]:
        """Get metadata about the expected response."""
        
        metadata = {
            "estimated_length": self._estimate_response_length(query, classification),
            "expected_sections": self._get_expected_sections(classification.intent),
            "difficulty_match": self._assess_difficulty_match(query, context.difficulty_level),
            "suggested_followups": self._generate_followup_suggestions(classification.intent)
        }
        
        return metadata
    
    def _estimate_response_length(self, query: str, classification: ClassificationResult) -> str:
        """Estimate response length based on query complexity and intent."""
        
        query_length = len(query.split())
        
        if classification.intent == "clarify" or query_length < 5:
            return "short"  # 1-2 paragraphs
        elif classification.intent == "solve" or query_length > 15:
            return "long"   # 3+ paragraphs
        else:
            return "medium" # 2-3 paragraphs
    
    def _get_expected_sections(self, intent: str) -> List[str]:
        """Get expected sections in the response."""
        
        section_map = {
            "explain": ["Definition", "Key Concepts", "Examples", "Applications"],
            "solve": ["Problem Analysis", "Solution Steps", "Verification", "Alternative Approaches"],
            "clarify": ["Clarification", "Detailed Explanation", "Common Misconceptions"],
            "example": ["Example Scenario", "Step-by-step Breakdown", "Key Takeaways"]
        }
        
        return section_map.get(intent, ["Introduction", "Main Content", "Summary"])
    
    def _assess_difficulty_match(self, query: str, user_level: str) -> str:
        """Assess if query difficulty matches user level."""
        
        # Simple heuristic based on query complexity
        complex_indicators = ["derivative", "integral", "quantum", "molecular", "algorithm"]
        simple_indicators = ["what is", "how do", "explain", "basic"]
        
        query_lower = query.lower()
        is_complex = any(indicator in query_lower for indicator in complex_indicators)
        is_simple = any(indicator in query_lower for indicator in simple_indicators)
        
        if user_level == "beginner":
            if is_complex:
                return "above_level"
            else:
                return "appropriate"
        elif user_level == "advanced":
            if is_simple:
                return "below_level" 
            else:
                return "appropriate"
        else:  # intermediate
            return "appropriate"
    
    def _generate_followup_suggestions(self, intent: str) -> List[str]:
        """Generate suggested follow-up questions."""
        
        suggestions_map = {
            "explain": [
                "Can you provide more examples?",
                "How does this relate to other concepts?",
                "What are the practical applications?"
            ],
            "solve": [
                "Can you show me a similar problem?",
                "What if the parameters were different?",
                "Are there alternative solution methods?"
            ],
            "clarify": [
                "Can you elaborate on that point?",
                "How does this connect to what we discussed before?",
                "Can you provide a concrete example?"
            ],
            "example": [
                "Can you show me a more complex example?",
                "How would this work in a different context?",
                "What are the key patterns to remember?"
            ]
        }
        
        return suggestions_map.get(intent, [])
    
    async def health_check(self) -> bool:
        """Check if tutor agent is healthy and can generate responses."""
        try:
            test_context = UserContext(
                current_subject="test",
                difficulty_level="intermediate"
            )
            
            test_classification = ClassificationResult(
                intent="explain",
                confidence=0.8,
                processing_time_ms=100
            )
            
            # Test response generation (first few chunks)
            chunk_count = 0
            async for chunk in self.generate_streaming_response(
                "Test query", test_context, test_classification
            ):
                chunk_count += 1
                if chunk_count >= 3:  # Just test first few chunks
                    break
            
            return chunk_count > 0
            
        except Exception as e:
            logger.error(f"Tutor agent health check failed: {e}")
            return False

# Global instance
tutor_agent = TutorAgent()